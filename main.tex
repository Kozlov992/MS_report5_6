\documentclass[a4paper]{article}
\input{header}
\begin{document}
\input{title}
\tableofcontents
\addtocontents{toc}{~\hfill\textbf{Страница}\par}
\newpage
\listoffigures
\addtocontents{lof}{~\hfill\textbf{Страница}\par}
\newpage
\listoftables
\addtocontents{lot}{~\hfill\textbf{Страница}\par}
\newpage
\section{Постановка задачи}
\begin{enumerate}
    \item Сгенерировать двумерные выборки размерами $20,\,60,\,100$ для нормального двумерного распределения $N(x,y,0,0,1,1,\rho)$.\\
    Коэффициент корреляции $\rho$ взять равным $0,\,0.5,\,0.9$.\\
    Каждая выборка генерируется $1000$ раз и для неё вычисляются: среднее значение, среднее значение квадрата и дисперсия коэффициентов корреляции Пирсона, Спирмена и квадрантного коэффициента корреляции.\\
    Повторить все вычисления для смеси нормальных распределений:
    \begin{equation*}
        f(x,y)=0.9N(x,y,0,0,1,1,0.9)+0.1N(x,y,0,0,10,10,-0.9).
    \end{equation*}
    Изобразить сгенерированные точки на плоскости и нарисовать эллипс
    равновероятности.
    \item Найти оценки коэффициентов линейной регрессии $y_i=a+b x_i + e_i$, используя 20 точек на отрезке $[-1.8,2]$ с равномерным шагом, равным $0.2$. Ошибку $e_i$ считать нормально распределенной с параметрами $(0,1)$. В качестве эталонной зависимости взять $y_i=2+2x_i+e_i$. При построении оценок использовать 2 критерия: критерий наименьших квадратов и критерий наименьших модулей. Проделать то же самое для выборки, у которой в значения $y_1$ и $y_{20}$ вносятся возмущения $10$ и $-10$.
    \item Сгенерировать выборку объемом 100 элементов для стандартного нормального распределения. В качестве основной гипотезы $H_0$ считать, что наблюдаемая выборка принадлежит стандартному нормальному распределению. Проверить основную гипотезу, используя критерий согласия $\chi^2$. В качестве уровня значимости взять $\alpha=0.05$. Привести таблицу вычислений $\chi^2$.\\
    Исследовать точность критерия $\chi^2\;-$ сгенерировать выборки равномерного распределения и распределения Лапласа объемом 20 элементов и проверить их на нормальность.
\end{enumerate}
\section{Теория}
\subsection{Двумерное нормальное распределение}
Двумерная случайная величина $(X, Y)$ называется распределенной нормально, если её плотность вероятности определяется формулой
\begin{align}
    N(x,y,\overline{x},\overline{y},\sigma_x,\sigma_y,\rho_{XY}^{})&=\frac{1}{2\pi\sigma_x\sigma_y\sqrt{1-\rho_{XY}^2}}\times\nonumber\\
    &\times\exp\left\{-\frac{1}{2(1-\rho_{XY}^2)}\left[\frac{\left(x-\overline{x}\right)^2}{\sigma_x^2}-2\rho_{XY}^{}\frac{(x-\overline{x})(y-\overline{y})}{\sigma_x\sigma_y}+\frac{\left(y-\overline{y}\right)^2}{\sigma_y^2}\right]\right\},
\end{align}
где $\overline{x},\,\overline{y},\sigma_x,\sigma_y$ - математические ожидания и средние квадратические отклонения компонент $X,\,Y$ соответственно, а $\rho_{XY}^{}\:-$ коэффициент корреляции. 
\subsection{Корреляционный момент и коэффициент корреляции}
\textit{Корреляционный момент} (\textit{ковариация}) двух случайных величин $X, Y$:
\begin{equation}
    K_{XY} = \cov{(X,Y)}=\mathbf{M}\left[(X-\overline{x})(Y-\overline{y})\right].
\end{equation}
\textit{Коэффициент корреляции} $\rho_{XY}$ случайных величин $X,Y$:
\begin{equation}\label{eq::rho}
    \rho_{XY}^{}=\frac{K_{XY}}{\sigma_x\sigma_y}.
\end{equation}
\textit{Ковариационной матрицей} случайного вектора $(X,Y)$ называется симметричная матрица вида
\begin{equation}
    K=\begin{pmatrix}
    D_X & K_{XY} \\
    K_{YX} & D_Y
    \end{pmatrix}.
\end{equation}
\textit{Кореляционной матрицей} случайного вектора $(X,Y)$ называется нормированная ковариационная матрица вида
\begin{equation}
    R=\begin{pmatrix}
    1 & \rho_{XY}^{} \\
    \rho_{YX}^{} & 1
    \end{pmatrix}.
\end{equation}
\subsection{Выборочные коэффициенты корреляции}
\subsubsection{Выборочный коэффициент корреляции Пирсона}
\textit{Выборочный коэффициент корреляции Пирсона}:
\begin{equation}\label{eq::pirs}
    r=\frac{\frac{1}{n}\sum_{i=1}^n \left(x_i-\overline{x}\right)\left(y_i-\overline{y}\right)}{\sqrt{\frac{1}{n}\sum_{i=1}^n\left(x_i-\overline{x}\right)^2 \frac{1}{n}\sum_{i=1}^n\left(y_i-\overline{y}\right)^2}}=\frac{K_{XY}}{s_X s_Y},
\end{equation}
где $K,\,s_X^2,\,s_Y^2\:-$ выборочные ковариация и дисперсии случайных величин $X, Y$.
\subsubsection{Выборочный коэффициент ранговой корреляции Спирмена}
Обозначим ранги, соотвествующие значениям переменной $X$, через $u$, а ранги, соответствующие значениям переменной $Y$, $-$ через $v$.
\\\\
\textit{Выборочный коэффициент ранговой корреляции Спирмена}:
\begin{equation}\label{eq::spir}
    r_S=\frac{\frac{1}{n}\sum_{i=1}^n \left(u_i-\overline{u}\right)\left(v_i-\overline{v}\right)}{\sqrt{\frac{1}{n}\sum_{i=1}^n\left(u_i-\overline{u}\right)^2 \frac{1}{n}\sum_{i=1}^n\left(v_i-\overline{v}\right)^2}},
\end{equation}
где $\overline{u}=\overline{v}=\frac{1+2+...+n}{n}=\frac{n+1}{2}\,-$ среднее значение рангов.
\subsubsection{Выборочный квадрантный коэффициент корреляции}
\begin{equation}\label{eq::rQ}
    r_Q=\frac{(n_1+n_3)-(n_2+n_4)}{n},
\end{equation}
где $n_1,n_2,n_3,n_4\:-$ количества точек с координатами $(x_i,y_i)$, попавшими соответственно в I, II, III и IV квадранты декартовой системы с осями $x^'=x-\med{x},\,y^'=y-\med{y}$ и с центром в точке с координатами $(\med{x},\med{y})$.
\subsection{Эллипсы рассеивания}
Уравнение проекции эллипса рассеивания на плоскость $xOy$:
\begin{equation}\label{eq:ellipse}
    \frac{\left(x-\overline{x}\right)^2}{\sigma_x^2}-2\rho_{XY}^{}\frac{(x-\overline{x})(y-\overline{y})}{\sigma_x\sigma_y}+\frac{\left(y-\overline{y}\right)^2}{\sigma_y^2}=C,\;\;C\,-\,\text{const}.
\end{equation}
Центр эллипса \eqref{eq:ellipse} находится в точке с координатами $(\overline{x},\overline{y})$, оси симметрии эллипса составляют с осью $Ox$ углы, определяемые уравнением
\begin{equation}
    \tan{2\alpha}=\frac{2\rho_{XY}^{}\sigma_x\sigma_y}{\sigma_x^2-\sigma_y^2}.
\end{equation}
\subsection{Простая линейная регрессия}
\subsubsection{Модель простой линейной регрессии}
Регрессионую модель описания данных называют \textit{простой линейной регрессией}, если
\begin{equation}
    y_i=\beta_0 + \beta_1 x_i + \varepsilon_i,\;\;i=1,...,n,
\end{equation}
где $x_1, ..., x_n\:-$ заданные числа (значения фактора); $y_1,...,y_n\:-$ наблюдаемые значения отклика; $\varepsilon_1,...,\varepsilon_n\:-$ независимые, нормально распределенные $N(0,\sigma)$ с нулевым математическим ожиданием и одинаковой (неизвестной) дисперсией случайные величины (ненаблюдаемые); $\beta_0,\:\beta_1\:-$ неизвестные параметры, подлежащие оцениванию.
\subsubsection{Метод наименьших квадратов}
\textit{Метод наименьших квадратов} (МНК):
\begin{equation}
    Q\left(\beta_0,\beta_1\right)=\sum_{i=1}^n \varepsilon_i^2= \sum_{i=1}^n\left(y_i-\beta_0-\beta_1 x_i\right)^2\to\min_{\beta_0,\beta_1}.
\end{equation}
\subsubsection{Расчётные формулы для МНК-оценок}
МНК-оценки параметров $\beta_0$ и $\beta_1$:
\begin{equation}
    \widehat{\beta}_1=\frac{\overline{xy}-\overline{x}\cdot\overline{y}}{\overline{x^2}-(\overline{x})^2},
\end{equation}
\begin{equation}
    \widehat{\beta}_0=\overline{y}-\overline{x}\widehat{\beta}_1.
\end{equation}
\subsection{Робастные оценки коэффициентов линейной регрессии}
\textit{Метод наименьших модулей}:
\begin{equation}
    \sum_{i=1}^n |y_i-\beta_0-\beta_1 x_i|\to \min_{\beta_0,\beta_1}.
\end{equation}
\begin{equation}
    \widehat{\beta}_{1R}=r_Q\frac{q_y^*}{q_x^*},
\end{equation}
\begin{equation}
    \widehat{\beta}_{0R}=\med{y}-\widehat{\beta}_{1R}\med{x},
\end{equation}
\begin{equation}
    r_Q=\frac{1}{n}\sum_{i=1}^n \sign{(x_i-\med{x})}\sign{(y_i-\med{y})},
\end{equation}
\begin{equation}
    q_y^*=\frac{y_{(j)}-y_{(l)}}{k_q(n)},\;\;q_x^*=\frac{x_{(j)}-x_{(l)}}{k_q(n)},
\end{equation}
\begin{equation*}
    \sign{z} = [z>0] - [z<0],\;\;[\,.\,]-\text{скобка Айверсона},
\end{equation*}
\begin{equation*}
    l = \lfloor n/4 \rfloor + \left[\,n/4 \not\in \mathbb{Z}\,\right],
\end{equation*}
\begin{equation*}
    j=n-l+1.
\end{equation*}
Уравнение регрессии здесь имеет вид
\begin{equation}
    y = \widehat{\beta}_{0R}+\widehat{\beta}_{1R} x.
\end{equation}
\begin{equation*}
    k_q(20)=1.491.
\end{equation*}
\subsection{Проверка гипотезы о законе распределения генеральной совокупности. Метод хи-квадрат}
Выдвинута гипотеза $H_0$ о генеральном законе распределения с функцией
распределения $F(x)$.\\
Рассматриваем случай, когда гипотетическая функция распределения $F(x)$ не содержит неизвестных параметров.\\
Для вычисления $k$ будем руководствоваться формулой
\begin{equation*}
    k\approx 1.72\sqrt[3]{n}.
\end{equation*}
\subsubsection*{Правило проверки гипотезы о законе распределения по методу $\chi^2$}
\begin{enumerate}
    \item Выбираем уровень значимости $\alpha$.
    \item По таблице \cite[с. 572-573]{book1} находим квантиль $\chi_{1-\alpha}^2(k-1)$ распределения хи-квадрат с $k-1$ степенями свободы порядка $1-\alpha$.
    \item Вычисляем вероятности $p_i=P(X\in\Delta_i), i = 1,...,k$, с помощью гипотетической функции распределения $F(x)$.
    \item Находим частоты $n_i$ попадания элементов выборки в подмножества $\Delta_i,i=1,...,k$.
    \item Вычисляем выборочное значение статистики критерия $\chi^2$:
        \begin{equation*}
            \chi^2_{\text{В}}=\sum_{i=1}^k\frac{(n_i-np_i)^2}{np_i}.
        \end{equation*}
    \item Сравниваем $\chi^2_{\text{В}}$ и квантиль $\chi_{1-\alpha}^2(k-1)$.
        \begin{enumerate}
            \item Если $\chi^2_{\text{В}}<\chi_{1-\alpha}^2(k-1)$, то гипотеза $H_0$ на данном этапе проверки принимается.
            \item Если $\chi^2_{\text{В}}\geq\chi_{1-\alpha}^2(k-1)$, то гипотеза $H_0$ отвергается, выбирается одно из альтернативных распределений, и процедура проверки повторяется.

        \end{enumerate}
\end{enumerate}
\section{Реализация}
Лабораторная работа выполнена на языках Python и R в средах PyCharm, Jupyter Notebook, R Studio с использованием следующих библиотек:
\begin{itemize}
    \item Python:
    \begin{enumerate}
        \item scipy (генерация выборок)
        \item statsmodels (построение э. ф. р.)
        \item matplotlib, seaborn (визуализация, построение гистограмм и боксплотов)
        \item numpy (вычисление ряда числовых характеристик)
    \end{enumerate}
    \item R:
    \begin{enumerate}
        \item MASS (генерация выборок)
        \item kableExtra (оформление)
        \item ggplot2, cowplot (визуализация данных)
        
\end{enumerate}
\end{itemize}
\section{Результаты}
\subsection{Выборочные коэффициенты корреляции}
\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|}
    \hline 
    \input{LabSrcs/resources/20rho0}
    \end{tabular}\\
    \begin{center}
        \includegraphics[]{LabSrcs/resources/20rho0.5.pdf}
    \end{center}
    \begin{center}
        \includegraphics{LabSrcs/resources/20rho0.9.pdf}
    \end{center}
    \caption{Двумерное нормальное распределение, $n=20$}
    \label{tab:norm20}
\end{table}
\begin{table}[H]
    \begin{center}
    \includegraphics[]{LabSrcs/resources/60rho0.pdf}
    \end{center}
    \begin{center}
    \includegraphics[]{LabSrcs/resources/60rho0.5.pdf}
    \end{center}
    \begin{center}
    \includegraphics[]{LabSrcs/resources/60rho0.9.pdf}
    \end{center}
    \caption{Двумерное нормальное распределение, $n=60$}
    \label{tab:norm60}
\end{table}
\begin{table}[H]
    \begin{center}
    \includegraphics[]{LabSrcs/resources/100rho0.pdf}
    \end{center}
    \begin{center}
    \includegraphics[]{LabSrcs/resources/100rho0.5.pdf}
    \end{center}
    \begin{center}
    \includegraphics[]{LabSrcs/resources/100rho0.9.pdf}
    \end{center}
    \caption{Двумерное нормальное распределение, $n=100$}
    \label{tab:norm100}
\end{table}
\begin{table}[H]
    \begin{center}
    \includegraphics[]{LabSrcs/resources/mixedDistr20.pdf}
    \end{center}
    \begin{center}
    \includegraphics[]{LabSrcs/resources/mixedDistr60.pdf}
    \end{center}
    \begin{center}
    \includegraphics[]{LabSrcs/resources/mixedDistr100.pdf}
    \end{center}
    \caption{Смесь нормальных распределений}
    \label{tab:mixture}
\end{table}
\subsection{Эллипсы рассеивания}
\begin{figure}[H]
    \centering
    \includegraphics[width = \textwidth, height = 7 cm]{LabSrcs/resources/ellipse20.pdf}
    \caption{Двумерное нормальное распределение, $n=20$}
    \label{fig:el20}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width = \textwidth, height = 7 cm]{LabSrcs/resources/ellipse60.pdf}
    \caption{Двумерное нормальное распределение, $n=60$}
    \label{fig:el60}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width = \textwidth, height = 7 cm]{LabSrcs/resources/ellipse100.pdf}
    \caption{Двумерное нормальное распределение, $n=100$}
    \label{fig:el100}
\end{figure}
\subsection{Оценки коэффициентов линейной регрессии}
\subsubsection{Выборка без возмущения}
\begin{itemize}
    \item Критерий наименьших квадратов:
    \[
    \input{LabSrcs/resources/us_LS_coeffs}.
    \]
    \item Критерий наименьших модулей:
    \[
    \input{LabSrcs/resources/us_LAD_coeffs}.
    \]
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width = 12 cm ]{LabSrcs/resources/usual_sample_regression.pdf}
    \caption{Выборка без возмущений}
    \label{fig:usr}
\end{figure}
\subsubsection{Выборка с возмущениями}
\begin{itemize}
    \item Критерий наименьших квадратов:
    \[
    \input{LabSrcs/resources/pert_LS_coeffs}.
    \]
    \item Критерий наименьших модулей:
    \[
    \input{LabSrcs/resources/pert_LAD_coeffs}.
    \]
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width = 12 cm ]{LabSrcs/resources/perturbated_sample_regression.pdf}
    \caption{Выборка c возмущениями}
    \label{fig:perr}
\end{figure}
\subsection{Проверка гипотезы о законе распределения генеральной совокупности. Метод хи-квадрат}
\begin{itemize}
    \item Количество промежутков $k=1.72\sqrt[3]{100}=7.984\approx8$,
    \item Уровень значимости $\alpha=0.05$,
    \item Квантиль из таблицы $\chi^2_{0.95}(7)\approx 14.1$.
\end{itemize}
\section{Обсуждение}
\section*{Примечание}
\begin{thebibliography}{9}
\bibitem{book1} 
 Вероятностные разделы математики. Учебник для бакалавров технических направлений.//Под ред. Максимова Ю.Д. $-$ Спб.: <<Иван Федоров>>, 2001. $-$ 592 c., илл.
\end{thebibliography}
\end{document}
